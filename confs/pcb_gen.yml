########################################################################
# Inference Configuration
########################################################################
algorithm: fj_ddim
model_path: checkpoint/checkpoint-256-defect-free.pt
crop_model_path: checkpoint/checkpoint-64-defect.pt
defect_free_dir: data/sample/
inpa_inj_sched_prev: true
n_jobs: 1
print_estimated_vars: true
inpa_inj_sched_prev_cumnoise: false
outdir: ./images/
n_samples: 4
n_iter: 1
debug: false
use_git: false
seed:
gd_mask_radius: 9
max_iter: 1000
cuda: 0

########################################################################
# Algorithm-Specific Configuration
########################################################################
attention_features:
  enabled: true
  temperature: 0.3  # Controls attention mask sharpness (lower = sharper)
  blur_sigma: 1.0  # Gaussian blur std for smoother boundaries
  
  # Center weighting mechanism
  center_weight: 1.0  # Center region weight strength (0.0-1.0)
  radial_decay: 0.15  # Radial decay rate from center to edges (0.0-1.0)
  
  # Connected component analysis
  connected_components: true
  min_area_ratio: 0.01  # Min area ratio for component filtering (0.0-1.0)
  center_region_ratio: 0.2  # Center region size for overlap detection (0.0-1.0)
  adaptive_threshold: true
  threshold_factor: 0.6  # Adaptive threshold scaling factor (0.0-1.0)

  # Attention accumulation
  accumulation_enabled: true
  accumulation_beta: 0.9  # EMA coefficient for attention accumulation (0.0-1.0)
  adaptive_beta: true
  beta_min: 0.5  # Min beta value when adaptive_beta is enabled
  
ddim:
  ddim_sigma: 0.0
  schedule_params:
    num_inference_steps: 250
    ddpm_num_steps: 250
    schedule_type: linear
    jump_length: 10
    jump_n_sample: 3
    use_timetravel: True
    time_travel_filter_type: none
    start_step: 30

optimize_xt:
  optimize_xt: true
  num_iteration_optimize_xt: 4
  lr_xt: 0.1
  lr_crop: false
  lr_xt_decay: 1.012
  use_smart_lr_xt_decay: true
  use_adaptive_lr_xt: true
  coef_xt_reg: 0.0001
  coef_xt_reg_decay: 1.01
  mid_interval_num: 1
  optimize_before_time_travel: true

repaint:
  schedule_jump_params:
    t_T: 250
    n_sample: 1
    jump_length: 10
    jump_n_sample: 2
  inpa_inj_sched_prev: true
  inpa_inj_sched_prev_cumnoise: false

g_scha:
  start: 2
  end: 2
  stop: 0

########################################################################
# Data Configuration
########################################################################
gt_path: 
crop_class_json_path: './data/pcb.json'

########################################################################
# Model Configuration
########################################################################
image_size: 256
class_cond: false
use_fp16: False
channel_mult: '1, 1, 2, 3, 4, 4'
attention_resolutions: 16, 8
diffusion_steps: 1000
timestep_respacing: '250'
learn_sigma: true
noise_schedule: linear
num_channels: 128
num_head_channels: 32
num_heads: 4 
num_res_blocks: 2
resblock_updown: true
use_scale_shift_norm: true
classifier_scale: 4.0
lr_kernel_n_std: 2
num_samples: 100
show_progress: true
use_kl: false
predict_xstart: false
rescale_timesteps: false
rescale_learned_sigmas: false
num_heads_upsample: -1
dropout: 0.0
use_checkpoint: false
use_new_attention_order: false
clip_denoised: true
use_ddim: false
respace_interpolate: false
schedule_sampler: uniform
classifier_path:

crop:
  image_size: 64
  num_channels: 64
  num_res_blocks: 2
  channel_mult: "1, 2, 3, 4"
  learn_sigma: true
  class_cond: true
  use_checkpoint: false
  attention_resolutions: 16, 8
  num_heads: 4
  num_head_channels: 16
  num_heads_upsample: -1
  use_scale_shift_norm: true
  dropout: 0.0
  resblock_updown: true
  use_fp16: False
  use_new_attention_order: false

########################################################################
# Classifier Configuration
########################################################################
classifier_model_path: 
classifier_noised_model_path:
classifier_image_size: 64
classifier_use_fp16: False
classifier_channel_mult: "1, 2, 3, 4"
classifier_width: 64
classifier_depth: 2
classifier_attention_resolutions: "16, 8"
classifier_num_heads: 2
classifier_num_head_channels: 32
classifier_use_scale_shift_norm: True
classifier_resblock_updown: True
classifier_pool: "attention"
classifier_out_channels: 6
